#!/usr/bin/env python3
"""
CodeTopæ•°æ®è·å–è„šæœ¬
è·å–å®Œæ•´çš„1134é“é¢˜ç›®æ•°æ®å¹¶ç”ŸæˆSQLæ’å…¥è¯­å¥
"""

import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Any

def fetch_all_problems() -> Dict[str, Any]:
    """
    ä»CodeTop APIè·å–æ‰€æœ‰é¢˜ç›®æ•°æ®
    """
    url = "https://codetop.cc/api/questions"
    headers = {
        'Accept': 'application/json',
        'User-Agent': 'Mozilla/5.0 (compatible; CodeTopDataFetcher/1.0)',
        'Referer': 'https://codetop.cc/home'
    }
    
    print(f"æ­£åœ¨è·å–æ•°æ®: {url}")
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        print(f"æˆåŠŸè·å–æ•°æ®: æ€»å…±{data.get('count', 0)}é“é¢˜ç›®")
        return data
        
    except requests.RequestException as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}")
        return {}
    except json.JSONDecodeError as e:
        print(f"JSONè§£æå¤±è´¥: {e}")
        return {}

def map_difficulty(level: int) -> str:
    """
    æ˜ å°„éš¾åº¦ç­‰çº§
    1 = EASY, 2 = MEDIUM, 3 = HARD
    """
    mapping = {1: 'EASY', 2: 'MEDIUM', 3: 'HARD'}
    return mapping.get(level, 'MEDIUM')

def clean_html(content: str) -> str:
    """
    æ¸…ç†HTMLå†…å®¹ï¼Œä¿ç•™åŸºæœ¬ä¿¡æ¯
    """
    if not content:
        return ""
    # ç®€å•çš„HTMLæ¸…ç†ï¼Œä¿ç•™é‡è¦ä¿¡æ¯
    import re
    # ç§»é™¤HTMLæ ‡ç­¾ä½†ä¿ç•™å†…å®¹
    cleaned = re.sub(r'<[^>]+>', '', content)
    # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned[:200] + "..." if len(cleaned) > 200 else cleaned

def format_date(date_str: str) -> str:
    """
    æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²ä¸º YYYY-MM-DD æ ¼å¼
    """
    try:
        # è§£æISOæ ¼å¼çš„æ—¥æœŸæ—¶é—´
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        return dt.strftime('%Y-%m-%d')
    except:
        return '2025-08-01'

def classify_tags(title: str, difficulty: str) -> List[str]:
    """
    æ ¹æ®é¢˜ç›®æ ‡é¢˜å’Œéš¾åº¦æ¨æ–­æ ‡ç­¾
    """
    tags = []
    
    # åŸºäºæ ‡é¢˜å…³é”®è¯æ¨æ–­æ ‡ç­¾
    title_lower = title.lower()
    
    if any(word in title for word in ['æ•°ç»„', 'æœ€å¤§', 'æœ€å°', 'ç¬¬Kä¸ª', 'åˆå¹¶', 'æ’åº']):
        tags.append('æ•°ç»„')
    if any(word in title for word in ['å­—ç¬¦ä¸²', 'å­ä¸²', 'å›æ–‡']):
        tags.append('å­—ç¬¦ä¸²')
    if any(word in title for word in ['é“¾è¡¨', 'åè½¬', 'åˆå¹¶']):
        tags.append('é“¾è¡¨')
    if any(word in title for word in ['äºŒå‰æ ‘', 'æ ‘', 'éå†']):
        tags.append('æ ‘')
    if any(word in title for word in ['å“ˆå¸Œ', 'LRU', 'ç¼“å­˜']):
        tags.append('å“ˆå¸Œè¡¨')
    if any(word in title for word in ['æœç´¢', 'æŸ¥æ‰¾', 'æ—‹è½¬']):
        tags.append('äºŒåˆ†æŸ¥æ‰¾')
    if any(word in title for word in ['å²›å±¿', 'å›¾']):
        tags.append('æ·±åº¦ä¼˜å…ˆæœç´¢')
    if any(word in title for word in ['å±‚åº', 'å±‚æ¬¡']):
        tags.append('å¹¿åº¦ä¼˜å…ˆæœç´¢')
    if any(word in title for word in ['æ’åˆ—', 'ç»„åˆ']):
        tags.append('å›æº¯ç®—æ³•')
    if any(word in title for word in ['åŠ¨æ€', 'æœ€ä¼˜', 'æœ€é•¿', 'æœ€å¤§å’Œ']):
        tags.append('åŠ¨æ€è§„åˆ’')
    if any(word in title for word in ['æ ˆ', 'æ‹¬å·']):
        tags.append('æ ˆ')
    if any(word in title for word in ['å¿«é€Ÿæ’åº', 'æ’åº']):
        tags.append('æ’åº')
    if any(word in title for word in ['åŒæŒ‡é’ˆ', 'ä¸‰æ•°ä¹‹å’Œ', 'ä¸¤æ•°ä¹‹å’Œ']):
        tags.append('åŒæŒ‡é’ˆ')
    
    # å¦‚æœæ²¡æœ‰æ¨æ–­å‡ºæ ‡ç­¾ï¼Œæ ¹æ®éš¾åº¦ç»™é»˜è®¤æ ‡ç­¾
    if not tags:
        if difficulty == 'EASY':
            tags.append('åŸºç¡€ç®—æ³•')
        elif difficulty == 'HARD':
            tags.append('é«˜çº§ç®—æ³•')
        else:
            tags.append('ç®—æ³•')
    
    return tags

def get_frequency_level(frequency: int) -> str:
    """
    æ ¹æ®é¢‘åº¦æ•°å€¼è¿”å›é¢‘åº¦ç­‰çº§
    """
    if frequency >= 600:
        return 'VERY_HIGH'
    elif frequency >= 400:
        return 'HIGH'
    elif frequency >= 200:
        return 'MEDIUM'
    else:
        return 'LOW'

def generate_problem_sql(problems: List[Dict[str, Any]]) -> str:
    """
    ç”Ÿæˆé¢˜ç›®æ•°æ®çš„SQLæ’å…¥è¯­å¥
    """
    sql_lines = []
    sql_lines.append("-- CodeTopå®Œæ•´é¢˜ç›®æ•°æ® (åŸºäºAPIçœŸå®æ•°æ®)")
    sql_lines.append(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    sql_lines.append(f"-- æ€»é¢˜ç›®æ•°é‡: {len(problems)}")
    sql_lines.append("")
    sql_lines.append("INSERT INTO problems (title, difficulty, problem_url, leetcode_id, tags, is_premium, is_active) VALUES")
    
    problem_values = []
    
    for i, item in enumerate(problems):
        try:
            leetcode_info = item.get('leetcode', {})
            
            title = leetcode_info.get('title', '').replace("'", "''")  # SQLè½¬ä¹‰
            leetcode_id = leetcode_info.get('frontend_question_id', str(i+1))
            difficulty = map_difficulty(leetcode_info.get('level', 2))
            slug = leetcode_info.get('slug_title', '')
            
            # æ„å»ºLeetCode URL
            if slug:
                problem_url = f"https://leetcode.cn/problems/{slug}"
            else:
                problem_url = f"https://leetcode.cn/problems/problem-{leetcode_id}"
            
            # æ¨æ–­æ ‡ç­¾
            tags = classify_tags(title, difficulty)
            tags_json = "JSON_ARRAY(" + ", ".join([f"'{tag}'" for tag in tags]) + ")"
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºä»˜è´¹é¢˜ç›® (ç®€å•åˆ¤æ–­é€»è¾‘)
            is_premium = 'true' if 'premium' in title.lower() or 'ä»˜è´¹' in title else 'false'
            
            problem_value = f"('{title}', '{difficulty}', '{problem_url}', '{leetcode_id}', {tags_json}, {is_premium}, true)"
            problem_values.append(problem_value)
            
        except Exception as e:
            print(f"å¤„ç†ç¬¬{i+1}ä¸ªé¢˜ç›®æ—¶å‡ºé”™: {e}")
            continue
    
    # åˆ†æ‰¹æ’å…¥ï¼Œæ¯æ‰¹100æ¡
    batch_size = 100
    for i in range(0, len(problem_values), batch_size):
        batch = problem_values[i:i+batch_size]
        if i > 0:
            sql_lines.append("\nINSERT INTO problems (title, difficulty, problem_url, leetcode_id, tags, is_premium, is_active) VALUES")
        
        for j, value in enumerate(batch):
            if j == len(batch) - 1:
                sql_lines.append(f"{value}")
            else:
                sql_lines.append(f"{value},")
        
        sql_lines.append("ON DUPLICATE KEY UPDATE")
        sql_lines.append("title = VALUES(title),")
        sql_lines.append("difficulty = VALUES(difficulty),")
        sql_lines.append("problem_url = VALUES(problem_url),")
        sql_lines.append("tags = VALUES(tags),")
        sql_lines.append("updated_at = CURRENT_TIMESTAMP;")
        sql_lines.append("")
    
    return "\n".join(sql_lines)

def generate_frequency_sql(problems: List[Dict[str, Any]]) -> str:
    """
    ç”Ÿæˆé¢‘åº¦å…³è”æ•°æ®çš„SQL
    """
    sql_lines = []
    sql_lines.append("-- é¢˜ç›®-å…¬å¸å…³è”æ•°æ® (åŸºäºçœŸå®é¢‘åº¦)")
    sql_lines.append("INSERT INTO problem_companies (problem_id, company_id, frequency, times_asked, last_asked_date)")
    sql_lines.append("SELECT")
    sql_lines.append("    p.id as problem_id,")
    sql_lines.append("    c.id as company_id,")
    sql_lines.append("    CASE")
    
    # ç”Ÿæˆé¢‘åº¦æ˜ å°„
    for item in problems[:50]:  # åªå¤„ç†å‰50ä¸ªé«˜é¢‘é¢˜ç›®
        try:
            leetcode_info = item.get('leetcode', {})
            leetcode_id = leetcode_info.get('frontend_question_id', '')
            frequency = item.get('value', 0)
            frequency_level = get_frequency_level(frequency)
            last_exam_date = format_date(item.get('time', ''))
            
            sql_lines.append(f"        WHEN p.leetcode_id = '{leetcode_id}' THEN '{frequency_level}'")
            
        except Exception as e:
            continue
    
    sql_lines.append("        ELSE 'LOW'")
    sql_lines.append("    END as frequency,")
    sql_lines.append("    CASE")
    
    # ç”ŸæˆçœŸå®é¢‘åº¦æ•°å€¼
    for item in problems[:50]:
        try:
            leetcode_info = item.get('leetcode', {})
            leetcode_id = leetcode_info.get('frontend_question_id', '')
            frequency = item.get('value', 0)
            
            sql_lines.append(f"        WHEN p.leetcode_id = '{leetcode_id}' THEN {frequency}")
            
        except Exception as e:
            continue
    
    sql_lines.append("        ELSE 50")
    sql_lines.append("    END as times_asked,")
    sql_lines.append("    CASE")
    
    # ç”Ÿæˆè€ƒå¯Ÿæ—¥æœŸ
    for item in problems[:50]:
        try:
            leetcode_info = item.get('leetcode', {})
            leetcode_id = leetcode_info.get('frontend_question_id', '')
            last_exam_date = format_date(item.get('time', ''))
            
            sql_lines.append(f"        WHEN p.leetcode_id = '{leetcode_id}' THEN '{last_exam_date}'")
            
        except Exception as e:
            continue
    
    sql_lines.append("        ELSE '2025-01-01'")
    sql_lines.append("    END as last_asked_date")
    sql_lines.append("FROM problems p")
    sql_lines.append("CROSS JOIN companies c")
    sql_lines.append("WHERE c.name IN ('bytedance', 'alibaba', 'tencent', 'baidu', 'microsoft', 'meituan')")
    sql_lines.append("ON DUPLICATE KEY UPDATE")
    sql_lines.append("frequency = VALUES(frequency),")
    sql_lines.append("times_asked = VALUES(times_asked),")
    sql_lines.append("last_asked_date = VALUES(last_asked_date),")
    sql_lines.append("updated_at = CURRENT_TIMESTAMP;")
    
    return "\n".join(sql_lines)

def main():
    print("=== CodeTopæ•°æ®è·å–å·¥å…· ===")
    
    # è·å–æ•°æ®
    data = fetch_all_problems()
    if not data or 'list' not in data:
        print("âŒ æ•°æ®è·å–å¤±è´¥")
        return
    
    problems = data['list']
    total_count = data.get('count', len(problems))
    
    print(f"âœ… æˆåŠŸè·å– {len(problems)} é“é¢˜ç›®æ•°æ® (æ€»è®¡: {total_count})")
    
    # æŒ‰é¢‘åº¦æ’åº
    problems.sort(key=lambda x: x.get('value', 0), reverse=True)
    
    # ç”ŸæˆSQL
    print("ğŸ“ ç”ŸæˆSQLæ–‡ä»¶...")
    
    # ç”Ÿæˆé¢˜ç›®æ•°æ®SQL
    problems_sql = generate_problem_sql(problems)
    
    # ç”Ÿæˆé¢‘åº¦å…³è”SQL  
    frequency_sql = generate_frequency_sql(problems)
    
    # å†™å…¥å®Œæ•´SQLæ–‡ä»¶
    complete_sql = f"""-- CodeTopå®Œæ•´æ•°æ®åº“å¯¼å…¥æ–‡ä»¶
-- æ•°æ®æ¥æº: https://codetop.cc/api/questions
-- æ€»é¢˜ç›®æ•°é‡: {len(problems)}
-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

-- ===================================
-- 1. æ’å…¥å…¬å¸æ•°æ®
-- ===================================

INSERT INTO companies (name, display_name, description, industry, is_active) VALUES
('bytedance', 'å­—èŠ‚è·³åŠ¨', 'Chinese multinational internet technology company', 'Technology', true),
('microsoft', 'å¾®è½¯', 'American multinational technology corporation', 'Technology', true),
('meituan', 'ç¾å›¢', 'Chinese food delivery and lifestyle platform', 'Technology', true),
('alibaba', 'é˜¿é‡Œå·´å·´', 'Chinese multinational technology conglomerate', 'Technology', true),
('kuaishou', 'å¿«æ‰‹', 'Chinese video sharing mobile app', 'Technology', true),
('tencent', 'è…¾è®¯', 'Chinese multinational technology conglomerate', 'Technology', true),
('yuanfudao', 'çŒ¿è¾…å¯¼', 'Chinese online education platform', 'Education', true),
('baidu', 'ç™¾åº¦', 'Chinese multinational technology company', 'Technology', true),
('didi', 'æ»´æ»´', 'Chinese vehicle for hire company', 'Transportation', true),
('jd', 'äº¬ä¸œ', 'Chinese e-commerce company', 'E-commerce', true),
('huawei', 'åä¸º', 'Chinese multinational technology corporation', 'Technology', true),
('pdd', 'æ‹¼å¤šå¤š', 'Chinese e-commerce platform', 'E-commerce', true),
('netease', 'ç½‘æ˜“', 'Chinese technology company', 'Technology', true),
('xiaomi', 'å°ç±³', 'Chinese electronics company', 'Technology', true),
('amazon', 'äºšé©¬é€Š', 'American multinational technology company', 'Technology', true),
('shopee', 'è™¾çš®', 'Singaporean e-commerce platform', 'E-commerce', true),
('ctrip', 'æºç¨‹', 'Chinese travel services company', 'Travel', true),
('bilibili', 'bilibili', 'Chinese video sharing website', 'Entertainment', true)
ON DUPLICATE KEY UPDATE 
display_name = VALUES(display_name),
description = VALUES(description),
industry = VALUES(industry),
is_active = VALUES(is_active),
updated_at = CURRENT_TIMESTAMP;

-- ===================================
-- 2. æ’å…¥é¢˜ç›®æ•°æ® (å…±{len(problems)}é“é¢˜ç›®)
-- ===================================

{problems_sql}

-- ===================================
-- 3. æ’å…¥é¢˜ç›®-å…¬å¸å…³è”æ•°æ®
-- ===================================

{frequency_sql}

-- ===================================
-- 4. åˆ›å»ºç»Ÿè®¡è§†å›¾
-- ===================================

CREATE OR REPLACE VIEW problem_frequency_stats AS
SELECT 
    p.leetcode_id,
    p.title,
    p.difficulty,
    p.problem_url,
    AVG(pc.times_asked) as avg_frequency,
    MAX(pc.times_asked) as max_frequency,
    COUNT(DISTINCT pc.company_id) as company_count,
    MAX(pc.last_asked_date) as latest_exam_date
FROM problems p
LEFT JOIN problem_companies pc ON p.id = pc.problem_id
WHERE p.deleted = 0 AND p.is_active = 1
GROUP BY p.id, p.leetcode_id, p.title, p.difficulty, p.problem_url
ORDER BY avg_frequency DESC;

-- ===================================
-- 5. æ•°æ®ç»Ÿè®¡éªŒè¯
-- ===================================

SELECT 
    'æ€»é¢˜ç›®æ•°é‡' as metric,
    COUNT(*) as count
FROM problems 
WHERE deleted = 0 AND is_active = 1;

SELECT 
    difficulty,
    COUNT(*) as count
FROM problems 
WHERE deleted = 0 AND is_active = 1
GROUP BY difficulty
ORDER BY 
    CASE difficulty 
        WHEN 'EASY' THEN 1 
        WHEN 'MEDIUM' THEN 2 
        WHEN 'HARD' THEN 3 
    END;

-- æ˜¾ç¤ºé¢‘åº¦æœ€é«˜çš„å‰10é“é¢˜
SELECT 
    p.leetcode_id,
    p.title,
    p.difficulty,
    AVG(pc.times_asked) as avg_frequency
FROM problems p
LEFT JOIN problem_companies pc ON p.id = pc.problem_id
WHERE p.deleted = 0 AND p.is_active = 1
GROUP BY p.id, p.leetcode_id, p.title, p.difficulty
ORDER BY avg_frequency DESC
LIMIT 10;
"""

    # ä¿å­˜æ–‡ä»¶
    output_file = '/mnt/e/FxxkLC/codetop_complete_data.sql'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(complete_sql)
    
    print(f"âœ… SQLæ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ€»é¢˜ç›®æ•°é‡: {len(problems)}")
    
    # ç»Ÿè®¡éš¾åº¦åˆ†å¸ƒ
    difficulty_count = {}
    for problem in problems:
        level = problem.get('leetcode', {}).get('level', 2)
        diff = map_difficulty(level)
        difficulty_count[diff] = difficulty_count.get(diff, 0) + 1
    
    for diff, count in difficulty_count.items():
        print(f"   - {diff}: {count}é“")
    
    # æ˜¾ç¤ºé¢‘åº¦æœ€é«˜çš„å‰5é“é¢˜
    print(f"\nğŸ”¥ é¢‘åº¦æœ€é«˜çš„å‰5é“é¢˜:")
    for i, problem in enumerate(problems[:5]):
        leetcode_info = problem.get('leetcode', {})
        title = leetcode_info.get('title', '')
        leetcode_id = leetcode_info.get('frontend_question_id', '')
        frequency = problem.get('value', 0)
        print(f"   {i+1}. {leetcode_id}. {title} (é¢‘åº¦: {frequency})")

if __name__ == "__main__":
    main()